{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1CqbtPqQ-4STYIlrVfj7OLj5gWMcODMV4","timestamp":1697909574941}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Text Generation using GPT-2 Language Model\n","\n","This notebook demonstrates text generation using the GPT-2 (Generative Pre-trained Transformer 2) language model, a state-of-the-art autoregressive language model developed by OpenAI. The notebook showcases how to utilize the 'transformers' library in Python to interact with GPT-2 and generate coherent and contextually relevant text based on a given prompt."],"metadata":{"id":"L9KNg9aZrDml"}},{"cell_type":"markdown","source":["## Importing Libraries\n","We start by importing the necessary libraries, including the 'transformers' library which provides access to pre-trained language models like GPT-2.\n","\n","The pre-trained GPT-2 model and tokenizer are loaded using the 'GPT2LMHeadModel' and 'GPT2Tokenizer' classes from the 'transformers' library. The GPT-2 model is set up for text generation."],"metadata":{"id":"av9r-C32rMPY"}},{"cell_type":"code","source":["!pip install transformers\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer"],"metadata":{"id":"iLnoKMQ9psvl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697909909711,"user_tz":-180,"elapsed":17540,"user":{"displayName":"Maha Bin Omirah","userId":"16941779132962004386"}},"outputId":"5cdf3a23-7eba-424e-8f10-8d4918fa321d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}]},{"cell_type":"markdown","source":["## Define the Text Generation Function\n","\n","A function named 'generate_text_with_gpt2()' is defined, which takes a prompt as input and uses the GPT-2 model to generate text based on the prompt. The function encodes the prompt, generates text using the GPT-2 model, and decodes the output to obtain human-readable text."],"metadata":{"id":"tRQFrOedrtJP"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"6UNTcfHIUH3H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the pre-trained GPT-2 model and tokenizer\n","model_name = \"gpt2\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)"],"metadata":{"id":"y71I2LkYTmP_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def generate_text_with_gpt2(prompt, max_length=100):\n","\n","    # Encode the prompt and generate text using GPT-2\n","    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n","    output_ids = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n","    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","    return output_text\n"],"metadata":{"id":"UTifQKdBrsos"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test the Function"],"metadata":{"id":"q_TCXsVlr6qo"}},{"cell_type":"markdown","source":["A sample prompt, such as \"Once upon a time,\" is provided to the 'generate_text_with_gpt2()' function, which generates text based on the prompt. The generated text is then displayed as the output."],"metadata":{"id":"25vkXkugr5a4"}},{"cell_type":"code","source":["\n","# Demo\n","prompt = \"Once upon a time\"\n","generated_text = generate_text_with_gpt2(prompt)\n","\n","print(\"Prompt:\")\n","print(prompt)\n","print(\"\\nGenerated Text:\")\n","print(generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kwm3J0HWr1al","executionInfo":{"status":"ok","timestamp":1697909922817,"user_tz":-180,"elapsed":7205,"user":{"displayName":"Maha Bin Omirah","userId":"16941779132962004386"}},"outputId":"2775f6a1-6609-47f4-d4eb-472e71adf535"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Prompt:\n","Once upon a time\n","\n","Generated Text:\n","Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great\n"]}]},{"cell_type":"markdown","source":["In the case of GPT-2, the model generates text by predicting the next token given the preceding tokens. While GPT-2 is a powerful language model, it is not explicitly trained to avoid generating repeated phrases or sentences. As a result, the model can sometimes get stuck in loops and generate repetitive patterns."],"metadata":{"id":"WKWH_UXbqaQS"}}]}